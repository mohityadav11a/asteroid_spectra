{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOobOpVx2o/Mc6rReVZSgEC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohityadav11a/asteroid_spectra/blob/main/data_fetch_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Abstract**\n",
        "This ML project is about classifying asteroid taxonomy spectra. We use over 1,000 spectra from [1] to train miscellaneous models to e.g., distinguish between the X class and non X class; to perform multi-label classification and unsupervised clustering using autoencoders."
      ],
      "metadata": {
        "id": "VznvbPbYRhZH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Data Fetching\n",
        "**References**\n",
        "\n",
        "[1] Url: http://smass.mit.edu/smass.html (Under 2)\n",
        "\n",
        "[2] Bus, Schelte J.; Compositional structure in the asteroid belt: results of a spectroscopic survey; Ph. D. Thesis; Massachusetts Institute of Technology, Dept. of Earth, Atmospheric, and Planetary Sciences; 1999"
      ],
      "metadata": {
        "id": "7tdrs-c6SKwl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zzUhg6rPD5S"
      },
      "outputs": [],
      "source": [
        "#Importing Modules\n",
        "import hashlib\n",
        "import os\n",
        "import pathlib\n",
        "import tarfile\n",
        "import urllib.request"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount the Google Drive, where we store files and models.\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/gdrive\")\n",
        "    core_path = \"/gdrive/MyDrive/colab/asteroid_taxonomy\"\n",
        "except ModuleNotFoundError:\n",
        "    core_path = \"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bM0FboxJPVKi",
        "outputId": "92bb97c4-9808-4692-eae5-1ae37b5c5805"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define function to compute the sha256 value of the downloaded files\n",
        "def comp_sha256(file_name):\n",
        "\n",
        "    # Set the SHA256 hashing\n",
        "    hash_sha256 = hashlib.sha256()\n",
        "\n",
        "    # Open the file in binary mode (read-only) and parse it in 65,536 byte chunks (in case of\n",
        "    # large files, the loading will not exceed the usable RAM)\n",
        "    with pathlib.Path(file_name).open(mode=\"rb\") as f_temp:\n",
        "        for _seq in iter(lambda: f_temp.read(65536), b\"\"):\n",
        "            hash_sha256.update(_seq)\n",
        "\n",
        "    # Digest the SHA256 result\n",
        "    sha256_res = hash_sha256.hexdigest()\n",
        "\n",
        "    return sha256_res"
      ],
      "metadata": {
        "id": "E7QSvY77RIHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the level0 data directory\n",
        "pathlib.Path(os.path.join(core_path, \"data/lvl0/\")).mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "_FrDndrhRLcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files_to_dl = \\\n",
        "    {'file1': {'url': 'http://smass.mit.edu/data/smass/Bus.Taxonomy.txt',\n",
        "               'sha256': '0ce970a6972dd7c49d512848b9736d00b621c9d6395a035bd1b4f3780d4b56c6'},\n",
        "     'file2': {'url': 'http://smass.mit.edu/data/smass/smass2data.tar.gz',\n",
        "               'sha256': 'dacf575eb1403c08bdfbffcd5dbfe12503a588e09b04ed19cc4572584a57fa97'}}"
      ],
      "metadata": {
        "id": "6U41LNq2Y0-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through the dictionary and download the files\n",
        "for dl_key in files_to_dl:\n",
        "\n",
        "    #  Extract filename from the URL\n",
        "    split = urllib.parse.urlsplit(files_to_dl[dl_key][\"url\"])\n",
        "    filename = pathlib.Path(os.path.join(core_path, \"data/lvl0/\", split.path.split(\"/\")[-1]))\n",
        "\n",
        "    # Check if file already exists locally\n",
        "    if not filename.is_file():\n",
        "\n",
        "        print(f\"Downloading now: {files_to_dl[dl_key]['url']}\")\n",
        "\n",
        "        # Download file and retrieve the created filepath\n",
        "        downl_file_path, _ = urllib.request.urlretrieve(url=files_to_dl[dl_key][\"url\"],\n",
        "                                                        filename=filename)\n",
        "\n",
        "        # Compute and compare the hash value\n",
        "        tax_hash = comp_sha256(downl_file_path)\n",
        "        assert tax_hash == files_to_dl[dl_key][\"sha256\"]"
      ],
      "metadata": {
        "id": "80WSTnElY2CZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Untar the spectra data\n",
        "tar = tarfile.open(os.path.join(core_path, \"data/lvl0/\", \"smass2data.tar.gz\"), \"r:gz\")\n",
        "tar.extractall(os.path.join(core_path, \"data/lvl0/\"))\n",
        "tar.close()"
      ],
      "metadata": {
        "id": "6yrTSX80Y2LR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
