{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzfgkXRy/QKuSTYFenR6J1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohityadav11a/asteroid_spectra/blob/main/data_parse_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Data Parsing\n",
        "This notebook takes now the downloaded files, parses and cleans the data and merges the taxonomy classification with the spectra data. The final dataset is stored in a Level 1 directory for further computations. Further, a first clean up is performed\n"
      ],
      "metadata": {
        "id": "9SdLogYVXJPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Libraries\n",
        "import glob\n",
        "import os\n",
        "import pathlib\n",
        "import re\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "tKU0YOlKXAGJ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount the Google Drive, where we store files and models.\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/gdrive')\n",
        "    core_path = \"/gdrive/MyDrive/colab/asteroid_taxonomy/\"\n",
        "except ModuleNotFoundError:\n",
        "    core_path = \"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_RIgkTkXs3F",
        "outputId": "2ab0a62d-e9b7-4acf-ded4-d164f406e5ac"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sorted list of all spectra files\n",
        "spectra_filepaths = sorted(glob.glob(os.path.join(core_path, \"data/lvl0/\", \"smass2/*spfit*\")))"
      ],
      "metadata": {
        "id": "h5RPXcwyYGNl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Asteroid Designation\n",
        "The spectra data have 2 different naming conventions starting with an \"a\" and starting with an \"au\". The first case corresponds to asteroids with an actual designation number (like (1) Ceres). The second case contains only temporary (at the time of the data release) designations (like 1995 BM2). Later, these spectra data need to be joined with the taxonomy class file\n"
      ],
      "metadata": {
        "id": "AP6X5Txh_9uw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate the filepaths into designation and non-designation files\n",
        "des_file_paths = spectra_filepaths[:-8]\n",
        "non_file_paths = spectra_filepaths[-8:]\n",
        "\n",
        "# Convert the arrays to dataframes\n",
        "des_file_paths_df = pd.DataFrame(des_file_paths, columns=[\"FilePath\"])\n",
        "non_file_paths_df = pd.DataFrame(non_file_paths, columns=[\"FilePath\"])\n",
        "\n",
        "# Add now the designation / \"non\"-designation number\n",
        "des_file_paths_df.loc[:, \"DesNr\"] = des_file_paths_df[\"FilePath\"].apply(lambda x: int(re.search(r'smass2/a(.*).spfit', x).group(1)))\n",
        "non_file_paths_df.loc[:, \"DesNr\"] = non_file_paths_df[\"FilePath\"].apply(lambda x: re.search(r'smass2/au(.*).spfit', x).group(1))"
      ],
      "metadata": {
        "id": "5bs_ymc6Zmco"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Taxonomy Classification\n",
        "We now read the taxonomy classification file. In theory, the file should contain only three columns: asteroid name, Tholen classification, and Bus classification. However, due to inconsistent formatting—such as irregular use of whitespace and tab characters—Pandas mistakenly identifies five columns instead.\n",
        "\n",
        "Since the additional columns cannot be reliably mapped to either the Tholen or Bus classification systems, the affected rows will be removed later."
      ],
      "metadata": {
        "id": "0sTxf-QiBv-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the classification file\n",
        "asteroid_class_df = pd.read_csv(os.path.join(core_path, \"data/lvl0/\", \"Bus.Taxonomy.txt\"),\n",
        "                                skiprows=21,\n",
        "                                sep=\"\\t\",\n",
        "                                names=[\"Name\",\n",
        "                                       \"Tholen_Class\",\n",
        "                                       \"Bus_Class\",\n",
        "                                       \"unknown1\",\n",
        "                                       \"unknown2\"\n",
        "                                      ]\n",
        "                               )\n",
        "\n",
        "# Remove white spaces\n",
        "asteroid_class_df.loc[:, \"Name\"] = asteroid_class_df[\"Name\"].apply(lambda x: x.strip()).copy()\n",
        "\n",
        "# Separate between designated and non-designated asteroid classes\n",
        "des_ast_class_df = asteroid_class_df[:1403].copy()\n",
        "non_ast_class_df = asteroid_class_df[1403:].copy()\n"
      ],
      "metadata": {
        "id": "ojkkJFzhaukR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now split the designated names and get the designation number (to link with the spfit files)\n",
        "des_ast_class_df.loc[:, \"DesNr\"] = des_ast_class_df[\"Name\"].apply(lambda x: int(x.split(\" \")[0]))\n",
        "\n",
        "# Merge with the spectra file paths\n",
        "des_ast_class_join_df = des_ast_class_df.merge(des_file_paths_df, on=\"DesNr\")\n",
        "\n",
        "# For the non designated names, remove the whitespaces\n",
        "non_ast_class_df.loc[:, \"DesNr\"] = non_ast_class_df[\"Name\"].apply(lambda x: x.replace(\" \", \"\"))\n",
        "\n",
        "# Merge with the spectra file paths\n",
        "non_ast_class_join_df = non_ast_class_df.merge(non_file_paths_df, on=\"DesNr\")"
      ],
      "metadata": {
        "id": "cbfo0_hvdFsS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oC0yk16AHnGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge now both datasets\n",
        "asteroids_df = pd.concat([des_ast_class_join_df, non_ast_class_join_df], axis=0)\n",
        "\n",
        "# Reset the index\n",
        "asteroids_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Remove the tholen class and both unknown columns\n",
        "asteroids_df.drop(columns=[\"Tholen_Class\", \"unknown1\", \"unknown2\"], inplace=True)\n",
        "\n",
        "# Drop now all rows that do not contains a Bus Class\n",
        "asteroids_df.dropna(subset=[\"Bus_Class\"], inplace=True)"
      ],
      "metadata": {
        "id": "5GFYX3d_emB4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read and store the Spectra into a dataframe\n"
      ],
      "metadata": {
        "id": "BNkHqyDnI7ne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read and store the spectra\n",
        "asteroids_df.loc[:, \"SpectrumDF\"] = \\\n",
        "    asteroids_df[\"FilePath\"].apply(lambda x: pd.read_csv(x, sep =  \"\\t\" , engine=\"python\",\n",
        "                                                         names=[\"Wavelength_in_microm\",\n",
        "                                                                \"Reflectance_norm550nm\"]\n",
        "                                                        )\n",
        "                                  )\n",
        "# Reset the index\n",
        "asteroids_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Convert the Designation Number to string\n",
        "asteroids_df.loc[:, \"DesNr\"] = asteroids_df[\"DesNr\"].astype(str)"
      ],
      "metadata": {
        "id": "5Qotbawziam2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the level 1 directory\n",
        "pathlib.Path(os.path.join(core_path, \"data/lvl1\")).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Save the dataframe as a pickle file\n",
        "asteroids_df.to_pickle(os.path.join(core_path, \"data/lvl1/\", \"asteroids_merged.pkl\"), protocol=4)"
      ],
      "metadata": {
        "id": "GCaNkLrdikjT"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}
